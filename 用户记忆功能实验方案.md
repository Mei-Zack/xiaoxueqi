# 糖尿病助手用户记忆功能实现方案

## 1. 需求分析

基于现有Vue3+TS前端和FastAPI后端的糖尿病助手项目，我们需要实现大模型记忆分析用户数据并提供个性化建议的功能。

### 1.1 核心需求

- 存储用户历史交互数据
- 实现大模型的记忆机制
- 分析用户数据并生成个性化建议
- 确保系统性能和数据隐私

## 2. 技术架构设计

### 2.1 数据存储层

```
+-------------------+      +-------------------+
|   MySQL数据库     |<---->|   ChromaDB向量库  |
| (结构化用户数据)  |      | (语义化对话记忆)  |
+-------------------+      +-------------------+
```

### 2.2 后端服务层

```
+-------------------+      +-------------------+      +-------------------+
|   FastAPI接口     |<---->|   记忆处理服务    |<---->|   Ollama模型服务  |
| (用户交互入口)    |      | (向量检索与分析)  |      | (生成个性化建议)  |
+-------------------+      +-------------------+      +-------------------+
```

### 2.3 前端展示层

```
+-------------------+
|   Vue3组件        |
| (个性化建议展示)  |
+-------------------+
```

## 3. 详细实现方案

### 3.1 数据库模型设计

```sql
-- 对话历史表
CREATE TABLE conversation_history (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    input_text TEXT NOT NULL,
    output_text TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- 用户特征表
CREATE TABLE user_profiles (
    user_id INT PRIMARY KEY,
    summary TEXT COMMENT '用户对话的总结摘要',
    preferences JSON COMMENT '用户偏好数据',
    health_data JSON COMMENT '健康相关数据',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- 用户洞察表
CREATE TABLE user_insights (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    insight_type VARCHAR(50) NOT NULL COMMENT '洞察类型：健康、饮食、行为等',
    insight_text TEXT NOT NULL COMMENT '洞察内容',
    confidence FLOAT COMMENT '置信度',
    generated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

### 3.2 向量存储服务实现

```python
# app/services/memory_store.py
import chromadb
from chromadb.utils import embedding_functions
import time
from typing import List, Dict, Any
import json

class MemoryStore:
    def __init__(self, persist_directory: str = "./vector_db"):
        """初始化向量存储服务"""
        self.client = chromadb.PersistentClient(path=persist_directory)
        # 使用sentence-transformers模型，适合中文语义理解
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="paraphrase-multilingual-MiniLM-L12-v2"  # 多语言模型，支持中文
        )
        # 创建或获取集合
        self.collection = self.client.get_or_create_collection(
            name="user_memories",
            embedding_function=self.embedding_fn,
            metadata={"description": "用户对话记忆"}
        )
    
    def add_memory(self, user_id: str, text: str, metadata: Dict[str, Any] = None):
        """添加记忆到向量数据库"""
        if metadata is None:
            metadata = {}
        
        # 确保metadata只包含可序列化的值
        metadata = {k: v for k, v in metadata.items() if isinstance(v, (str, int, float, bool))}
        metadata["user_id"] = str(user_id)
        metadata["timestamp"] = time.time()
        
        document_id = f"user_{user_id}_{int(metadata['timestamp'])}"
        
        try:
            self.collection.add(
                documents=[text],
                ids=[document_id],
                metadatas=[metadata]
            )
            return True
        except Exception as e:
            print(f"添加记忆失败: {e}")
            return False
    
    def retrieve_memories(self, user_id: str, query: str, n_results: int = 5):
        """检索与查询相关的记忆"""
        try:
            results = self.collection.query(
                query_texts=[query],
                where={"user_id": str(user_id)},
                n_results=n_results
            )
            return results["documents"][0], results["metadatas"][0]
        except Exception as e:
            print(f"检索记忆失败: {e}")
            return [], []
    
    def get_recent_memories(self, user_id: str, limit: int = 10):
        """获取用户最近的记忆"""
        try:
            # 注意：ChromaDB不支持直接按时间排序，需要获取所有后再排序
            results = self.collection.get(
                where={"user_id": str(user_id)},
                limit=100  # 获取较多记录以便后续筛选
            )
            
            # 将结果转换为列表并按时间戳排序
            memories = []
            for i, doc in enumerate(results["documents"]):
                memories.append({
                    "text": doc,
                    "metadata": results["metadatas"][i],
                    "id": results["ids"][i]
                })
            
            # 按时间戳降序排序并限制数量
            memories.sort(key=lambda x: x["metadata"].get("timestamp", 0), reverse=True)
            return memories[:limit]
        except Exception as e:
            print(f"获取最近记忆失败: {e}")
            return []
```

### 3.3 记忆处理服务

```python
# app/services/memory_processor.py
from app.db.models import User, ConversationHistory, UserProfile, UserInsight
from app.services.memory_store import MemoryStore
from app.ml.ollama_service import OllamaService
from sqlalchemy.orm import Session
from typing import List, Dict, Any
import json
import datetime

class MemoryProcessor:
    def __init__(self, db: Session, memory_store: MemoryStore, ollama_service: OllamaService):
        self.db = db
        self.memory_store = memory_store
        self.ollama_service = ollama_service
    
    async def process_conversation(self, user_id: int, input_text: str, output_text: str):
        """处理新的对话，存储并分析"""
        # 1. 存储到MySQL
        conversation = ConversationHistory(
            user_id=user_id,
            input_text=input_text,
            output_text=output_text
        )
        self.db.add(conversation)
        self.db.commit()
        
        # 2. 存储到向量数据库
        combined_text = f"用户: {input_text}\n助手: {output_text}"
        self.memory_store.add_memory(
            user_id=str(user_id),
            text=combined_text,
            metadata={
                "type": "conversation",
                "input": input_text[:100],  # 存储部分输入作为元数据
                "date": datetime.datetime.now().strftime("%Y-%m-%d")
            }
        )
        
        # 3. 异步触发用户洞察分析
        # 注意：实际项目中应使用Celery等任务队列
        await self.generate_insights(user_id)
        
        return conversation.id
    
    async def generate_insights(self, user_id: int):
        """生成用户洞察"""
        # 获取用户最近的对话
        recent_memories = self.memory_store.get_recent_memories(str(user_id), limit=10)
        if not recent_memories:
            return
        
        # 提取对话文本
        conversation_texts = [memory["text"] for memory in recent_memories]
        conversation_history = "\n\n".join(conversation_texts)
        
        # 构建分析提示词
        prompt = f"""
        请分析以下用户对话历史，提取关键洞察。特别关注与健康、饮食和行为相关的信息。
        提供3-5个关键洞察，每个洞察应包含具体观察和建议。
        
        对话历史:
        {conversation_history}
        
        请以JSON格式返回，格式如下:
        {{
            "insights": [
                {{
                    "type": "健康|饮食|行为|其他",
                    "observation": "观察到的事实",
                    "suggestion": "相关建议",
                    "confidence": 0.XX
                }}
            ]
        }}
        """
        
        # 调用Ollama生成洞察
        response = await self.ollama_service.generate(prompt)
        
        try:
            # 解析JSON响应
            insights_data = json.loads(response)
            
            # 存储洞察到数据库
            for insight in insights_data.get("insights", []):
                user_insight = UserInsight(
                    user_id=user_id,
                    insight_type=insight.get("type", "其他"),
                    insight_text=f"{insight.get('observation', '')} - {insight.get('suggestion', '')}",
                    confidence=insight.get("confidence", 0.5)
                )
                self.db.add(user_insight)
            
            self.db.commit()
            return insights_data
        except Exception as e:
            print(f"解析洞察失败: {e}")
            return None
    
    async def get_enhanced_context(self, user_id: int, current_input: str):
        """获取增强的上下文，用于大模型生成回复"""
        # 1. 获取用户基本信息
        user = self.db.query(User).filter(User.id == user_id).first()
        if not user:
            return ""
        
        # 2. 获取用户档案
        profile = self.db.query(UserProfile).filter(UserProfile.user_id == user_id).first()
        profile_summary = profile.summary if profile else "无用户档案信息"
        # 新增：解析健康数据
        health_info = "无健康数据"
        if profile and profile.health_data:
            try:
                health_data = json.loads(profile.health_data) if isinstance(profile.health_data, str) else profile.health_data
                # 假设health_data结构如下：{"glucose": [...], "weight": [...], ...}
                latest_glucose = health_data.get("glucose", [])[-1] if health_data.get("glucose") else None
                latest_weight = health_data.get("weight", [])[-1] if health_data.get("weight") else None
                latest_bmi = health_data.get("bmi", [])[-1] if health_data.get("bmi") else None
                # 可根据实际结构调整
                health_info = ""
                if latest_glucose:
                    health_info += f"最近血糖: {latest_glucose['value']} mmol/L（{latest_glucose['date']}）\n"
                if latest_weight:
                    health_info += f"最近体重: {latest_weight['value']} kg（{latest_weight['date']}）\n"
                if latest_bmi:
                    health_info += f"最近BMI: {latest_bmi['value']}（{latest_bmi['date']}）\n"
                if not health_info:
                    health_info = "暂无关键健康数据"
            except Exception as e:
                health_info = "健康数据解析异常"
        
        # 3. 检索相关历史对话
        relevant_memories, _ = self.memory_store.retrieve_memories(
            user_id=str(user_id),
            query=current_input,
            n_results=3
        )
        memory_context = "\n\n".join(relevant_memories) if relevant_memories else "无相关历史对话"
        
        # 4. 获取最新的用户洞察
        recent_insights = self.db.query(UserInsight)\
            .filter(UserInsight.user_id == user_id)\
            .order_by(UserInsight.generated_at.desc())\
            .limit(3)\
            .all()
        
        insights_text = ""
        if recent_insights:
            insights_text = "\n".join([f"- {insight.insight_text}" for insight in recent_insights])
        else:
            insights_text = "无用户洞察"
        
        # 5. 构建增强上下文（优化版）
        enhanced_context = f"""
        ## 用户信息
        用户名: {user.username}
        用户ID: {user.id}
        
        ## 用户档案摘要
        {profile_summary}
        
        ## 关键健康数据
        {health_info}
        
        ## 相关历史对话
        {memory_context}
        
        ## 用户洞察
        {insights_text}
        """
        
        return enhanced_context
```

### 3.4 FastAPI接口实现

```python
# app/api/endpoints/assistant.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.db.session import get_db
from app.api.deps import get_current_user
from app.services.memory_processor import MemoryProcessor
from app.services.memory_store import MemoryStore
from app.ml.ollama_service import OllamaService
from app.models.assistant import ChatRequest, ChatResponse
from typing import List

router = APIRouter()
memory_store = MemoryStore()
ollama_service = OllamaService()

@router.post("/chat", response_model=ChatResponse)
async def chat_with_assistant(
    request: ChatRequest,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """与具有记忆功能的助手对话"""
    try:
        # 初始化记忆处理器
        memory_processor = MemoryProcessor(db, memory_store, ollama_service)
        
        # 获取增强上下文
        enhanced_context = await memory_processor.get_enhanced_context(
            user_id=current_user.id,
            current_input=request.message
        )
        
        # 构建完整提示词
        full_prompt = f"""
        {enhanced_context}
        
        ## 当前对话
        用户: {request.message}
        
        请根据上述信息，以糖尿病助手的身份回答用户问题。回答应该考虑用户的历史信息和洞察，
        提供个性化、有帮助的建议。如果涉及健康建议，请确保基于科学依据。
        """
        
        # 调用Ollama生成回复
        response = await ollama_service.generate(full_prompt)
        
        # 处理并存储对话
        await memory_processor.process_conversation(
            user_id=current_user.id,
            input_text=request.message,
            output_text=response
        )
        
        return ChatResponse(response=response)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"处理对话失败: {str(e)}")

@router.get("/insights", response_model=List[dict])
async def get_user_insights(
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """获取用户洞察"""
    try:
        memory_processor = MemoryProcessor(db, memory_store, ollama_service)
        insights = await memory_processor.generate_insights(current_user.id)
        return insights.get("insights", []) if insights else []
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"获取洞察失败: {str(e)}")
```

### 3.5 前端组件实现

```vue
<!-- src/views/AssistantView.vue -->
<script setup lang="ts">
import { ref, onMounted } from 'vue'
import { useUserStore } from '@/stores/user'
import axios from '@/api'
import type { ChatMessage, UserInsight } from '@/types'

const userStore = useUserStore()
const messages = ref<ChatMessage[]>([])
const newMessage = ref('')
const insights = ref<UserInsight[]>([])
const isLoading = ref(false)
const isLoadingInsights = ref(false)

// 发送消息
const sendMessage = async () => {
  if (!newMessage.value.trim()) return
  
  const userMessage = newMessage.value
  messages.value.push({
    content: userMessage,
    role: 'user',
    timestamp: new Date()
  })
  
  newMessage.value = ''
  isLoading.value = true
  
  try {
    const response = await axios.post('/assistant/chat', {
      message: userMessage
    }, {
      timeout: 30000
    })
    
    messages.value.push({
      content: response.data.response,
      role: 'assistant',
      timestamp: new Date()
    })
    
    // 每次对话后更新洞察
    fetchInsights()
  } catch (error) {
    console.error('发送消息失败:', error)
    messages.value.push({
      content: '抱歉，处理您的消息时出现了问题。请稍后再试。',
      role: 'assistant',
      timestamp: new Date(),
      error: true
    })
  } finally {
    isLoading.value = false
  }
}

// 获取用户洞察
const fetchInsights = async () => {
  isLoadingInsights.value = true
  try {
    const response = await axios.get('/assistant/insights')
    insights.value = response.data
  } catch (error) {
    console.error('获取洞察失败:', error)
  } finally {
    isLoadingInsights.value = false
  }
}

onMounted(() => {
  // 初始化时获取洞察
  fetchInsights()
})
</script>

<template>
  <div class="assistant-container">
    <div class="chat-container">
      <div class="messages">
        <div 
          v-for="(msg, index) in messages" 
          :key="index"
          :class="['message', msg.role]"
        >
          <div class="message-content">{{ msg.content }}</div>
          <div class="message-time">
            {{ new Date(msg.timestamp).toLocaleTimeString() }}
          </div>
        </div>
        <div v-if="isLoading" class="message assistant loading">
          <div class="typing-indicator">
            <span></span><span></span><span></span>
          </div>
        </div>
      </div>
      
      <div class="message-input">
        <el-input
          v-model="newMessage"
          type="textarea"
          :rows="3"
          placeholder="请输入您的问题..."
          @keyup.enter.ctrl="sendMessage"
        />
        <el-button 
          type="primary" 
          @click="sendMessage"
          :loading="isLoading"
        >
          发送
        </el-button>
      </div>
    </div>
    
    <div class="insights-container">
      <h3>个性化洞察 <el-button size="small" @click="fetchInsights" :loading="isLoadingInsights">刷新</el-button></h3>
      <el-skeleton :loading="isLoadingInsights" animated>
        <template #default>
          <div v-if="insights.length > 0">
            <el-card v-for="(insight, index) in insights" :key="index" class="insight-card">
              <template #header>
                <div class="insight-header">
                  <span>{{ insight.type }}</span>
                  <el-tag size="small" :type="getConfidenceType(insight.confidence)">
                    置信度: {{ Math.round(insight.confidence * 100) }}%
                  </el-tag>
                </div>
              </template>
              <div class="insight-content">
                <p><strong>观察:</strong> {{ insight.observation }}</p>
                <p><strong>建议:</strong> {{ insight.suggestion }}</p>
              </div>
            </el-card>
          </div>
          <el-empty v-else description="暂无洞察数据" />
        </template>
      </el-skeleton>
    </div>
  </div>
</template>

<script lang="ts">
export default {
  name: 'AssistantView',
  methods: {
    getConfidenceType(confidence: number): string {
      if (confidence >= 0.8) return 'success'
      if (confidence >= 0.6) return 'warning'
      return 'info'
    }
  }
}
</script>

<style scoped>
.assistant-container {
  display: flex;
  height: calc(100vh - 120px);
}

.chat-container {
  flex: 3;
  display: flex;
  flex-direction: column;
  border-right: 1px solid #eee;
  padding: 20px;
}

.messages {
  flex: 1;
  overflow-y: auto;
  padding: 10px;
}

.message {
  margin-bottom: 15px;
  padding: 10px 15px;
  border-radius: 10px;
  max-width: 80%;
}

.message.user {
  background-color: #e6f7ff;
  align-self: flex-end;
  margin-left: auto;
}

.message.assistant {
  background-color: #f5f5f5;
  align-self: flex-start;
}

.message-time {
  font-size: 12px;
  color: #999;
  text-align: right;
  margin-top: 5px;
}

.message-input {
  margin-top: 20px;
  display: flex;
  gap: 10px;
}

.insights-container {
  flex: 1;
  padding: 20px;
  overflow-y: auto;
}

.insight-card {
  margin-bottom: 15px;
}

.insight-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.typing-indicator {
  display: flex;
  padding: 10px;
}

.typing-indicator span {
  height: 10px;
  width: 10px;
  background-color: #999;
  border-radius: 50%;
  display: inline-block;
  margin: 0 2px;
  animation: bounce 1.5s infinite ease-in-out;
}

.typing-indicator span:nth-child(2) {
  animation-delay: 0.2s;
}

.typing-indicator span:nth-child(3) {
  animation-delay: 0.4s;
}

@keyframes bounce {
  0%, 80%, 100% { 
    transform: translateY(0);
  }
  40% { 
    transform: translateY(-10px);
  }
}
</style>
```

## 4. 系统优化与注意事项

### 4.1 性能优化

❗️ **潜在性能瓶颈**

- 向量检索在用户量大时可能变慢
- Ollama模型调用可能导致高延迟

**优化方案**：

1. 实现多级缓存系统：

```python
# app/services/cache_service.py
import redis
import json
from typing import Any, Optional

class CacheService:
    def __init__(self, redis_url: str = "redis://localhost:6379/0"):
        self.redis = redis.from_url(redis_url)
        self.ttl = 3600  # 默认缓存1小时
    
    def set(self, key: str, value: Any, expire: int = None):
        """设置缓存"""
        serialized = json.dumps(value)
        self.redis.set(key, serialized, ex=expire or self.ttl)
    
    def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        data = self.redis.get(key)
        if data:
            return json.loads(data)
        return None
    
    def delete(self, key: str):
        """删除缓存"""
        self.redis.delete(key)
```

2. 异步处理洞察生成：

```python
# app/tasks.py
from celery import Celery
from app.services.memory_processor import MemoryProcessor
from app.db.session import SessionLocal
from app.services.memory_store import MemoryStore
from app.ml.ollama_service import OllamaService

celery = Celery(__name__)
celery.conf.broker_url = "redis://localhost:6379/1"
celery.conf.result_backend = "redis://localhost:6379/1"

@celery.task
def process_insights_task(user_id: int):
    """异步处理用户洞察"""
    db = SessionLocal()
    memory_store = MemoryStore()
    ollama_service = OllamaService()
    
    try:
        memory_processor = MemoryProcessor(db, memory_store, ollama_service)
        memory_processor.generate_insights(user_id)
    finally:
        db.close()
```

### 4.2 数据隐私与安全

❗️ **隐私风险**

- 用户敏感健康数据存储可能存在泄露风险
- 大模型可能意外泄露用户信息

**安全措施**：

1. 数据加密实现：

```python
# app/core/security.py
from cryptography.fernet import Fernet
import base64
import os

class DataEncryption:
    def __init__(self, key: str = None):
        if key is None:
            key = os.getenv("ENCRYPTION_KEY", Fernet.generate_key().decode())
        
        # 确保key是bytes类型
        if isinstance(key, str):
            key = key.encode()
        
        self.cipher = Fernet(key)
    
    def encrypt(self, data: str) -> str:
        """加密数据"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """解密数据"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
```

2. 用户数据匿名化：

```python
# app/utils/anonymizer.py
import re
import hashlib

class DataAnonymizer:
    @staticmethod
    def anonymize_health_data(data: dict) -> dict:
        """匿名化健康数据"""
        result = data.copy()
        
        # 移除或哈希敏感标识符
        if "name" in result:
            result["name"] = DataAnonymizer._hash_value(result["name"])
        
        if "id_number" in result:
            result["id_number"] = "***********"
        
        # 模糊化精确位置
        if "location" in result:
            result["location"] = result["location"].split(",")[0]  # 只保留城市
        
        return result
    
    @staticmethod
    def _hash_value(value: str) -> str:
        """对值进行哈希处理"""
        return hashlib.sha256(value.encode()).hexdigest()[:8]
```

### 4.3 扩展性设计

为支持未来功能扩展，建议实现以下接口：

```python
# app/services/memory_interface.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Tuple

class MemoryInterface(ABC):
    @abstractmethod
    def add_memory(self, user_id: str, text: str, metadata: Dict[str, Any] = None) -> bool:
        """添加记忆"""
        pass
    
    @abstractmethod
    def retrieve_memories(self, user_id: str, query: str, n_results: int = 5) -> Tuple[List[str], List[Dict]]:
        """检索记忆"""
        pass
    
    @abstractmethod
    def get_recent_memories(self, user_id: str, limit: int = 10) -> List[Dict]:
        """获取最近记忆"""
        pass
```

这样可以在未来轻松替换底层实现（如从ChromaDB切换到Pinecone或其他向量数据库）。

## 5. 部署与监控

### 5.1 部署架构

```
+------------------+       +------------------+
|   Nginx前端      |------>|   Vue3前端应用   |
+------------------+       +------------------+
        |                           |
        v                           v
+------------------+       +------------------+
|   FastAPI后端    |<----->|   Celery Worker  |
+------------------+       +------------------+
        |                           |
        v                           v
+------------------+       +------------------+
|   MySQL数据库    |       |   Redis缓存      |
+------------------+       +------------------+
        |                           |
        v                           v
+------------------+       +------------------+
|   ChromaDB       |       |   Ollama服务     |
+------------------+       +------------------+
```

### 5.2 监控指标

1. 系统健康指标：
   - API响应时间
   - 数据库查询性能
   - 向量检索延迟
   - Ollama调用成功率

2. 业务指标：
   - 用户交互频率
   - 建议采纳率（通过用户反馈）
   - 洞察生成质量

## 6. 实施路线图

### 6.1 阶段一：基础功能（2周）

- 实现数据库模型
- 集成ChromaDB向量存储
- 基本对话存储与检索

### 6.2 阶段二：记忆增强（2周）

- 实现上下文增强功能
- 添加用户洞察生成
- 前端展示组件开发

### 6.3 阶段三：优化与安全（1周）

- 性能优化与缓存
- 数据隐私保护实现
- 监控系统部署

## 7. 潜在问题与解决方案

❗️ **数据稀疏问题**

- **问题**：新用户数据不足，无法生成有效洞察
- **解决方案**：实现冷启

## 8. 食物营养-血糖响应大模型训练方案

### 8.1 数据融合架构

为支持个性化血糖助手的训练，我们需要融合三类核心数据：

```
+-------------------+     +-------------------+     +-------------------+
|   食物营养数据库   |---->|   用户饮食记录    |<----|   血糖监测数据    |
| (GI值、碳水等)    |     | (摄入量、时间等)  |     | (餐前餐后变化)    |
+-------------------+     +-------------------+     +-------------------+
              \                    |                       /
               \                   v                      /
                +--------->+-------------------+<---------+
                           |  训练样本生成器   |
                           | (特征提取与标注)  |
                           +-------------------+
                                    |
                                    v
                           +-------------------+
                           |   本地大模型微调  |
                           | (LoRA/QLoRA方法) |
                           +-------------------+
```

### 8.2 数据模型扩展

```sql
-- 食物摄入记录表
CREATE TABLE food_intake (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    food_id INT NOT NULL,
    intake_datetime DATETIME NOT NULL,
    quantity FLOAT NOT NULL COMMENT '摄入量(克)',
    meal_type ENUM('breakfast', 'lunch', 'dinner', 'snack') NOT NULL,
    pre_glucose FLOAT COMMENT '餐前血糖值(mmol/L)',
    post_glucose FLOAT COMMENT '餐后血糖值(mmol/L)',
    post_time INT DEFAULT 120 COMMENT '餐后测量时间(分钟)',
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (food_id) REFERENCES food_nutrition(id)
);

-- 血糖响应模式表
CREATE TABLE glucose_response_patterns (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    pattern_type VARCHAR(50) NOT NULL COMMENT '响应模式类型',
    description TEXT NOT NULL,
    confidence FLOAT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

### 8.3 特征工程方案

特征工程是构建有效训练样本的关键，我们提取以下特征：

1. **食物特征**：
   - 基础营养素：卡路里、蛋白质、脂肪、碳水
   - 血糖指标：GI值、糖分含量
   - 食物类别：谷物、蔬菜、水果等类别的One-hot编码

2. **用户特征**：
   - 用户基础信息：年龄、BMI、糖尿病类型
   - 用户饮食习惯：偏好食物类别、常见进食时间

3. **时序特征**：
   - 进食时间特征：早餐/午餐/晚餐
   - 前后血糖测量间隔

4. **目标变量**：
   - 血糖变化幅度（餐后-餐前）
   - 血糖响应类别（平稳/轻微上升/显著上升）

### 8.4 模型训练策略

#### 8.4.1 基础模型选择

推荐使用以下开源中文基础模型之一：

- **ChatGLM3-6B**：清华开源，轻量级，适合本地部署
- **Baichuan2-7B/13B**：百川智能，中文理解能力强
- **Qwen-7B**：阿里通义千问，指令理解能力优秀

#### 8.4.2 微调方法

采用低资源高效微调方法：

```python
# 示例：使用PEFT库的LoRA方法进行高效微调
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, TrainingArguments, Trainer

# 1. 加载基础模型
base_model = AutoModelForCausalLM.from_pretrained(
    "THUDM/chatglm3-6b",
    trust_remote_code=True,
    device_map="auto",
    torch_dtype=torch.float16
)

# 2. LoRA配置
lora_config = LoraConfig(
    r=16,                      # LoRA注意力维度
    lora_alpha=32,             # LoRA缩放因子
    target_modules=["query_key_value"],  # 目标模块
    lora_dropout=0.05,         # Dropout概率
    bias="none",               # 偏置处理方式
    task_type=TaskType.CAUSAL_LM  # 任务类型
)

# 3. 构建PEFT模型
model = get_peft_model(base_model, lora_config)

# 4. 训练配置
training_args = TrainingArguments(
    output_dir="./diabetes-assistant-model",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-5,
    weight_decay=0.01,
    warmup_steps=100,
    logging_steps=10,
    evaluation_strategy="steps",
    eval_steps=50,
    save_strategy="steps",
    save_steps=50,
)

# 5. 训练器
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    data_collator=data_collator,
)

# 6. 执行训练
trainer.train()
```

#### 8.4.3 训练数据格式

每个训练样本采用如下结构的指令模板：

```
<SYSTEM>
你是一位专业的糖尿病营养助手，基于用户的血糖反应历史和食物特性提供个性化建议。
</SYSTEM>

<USER>
我的基本信息：
- 年龄：{user_age}岁
- 体重：{user_weight}kg
- 糖尿病类型：{diabetes_type}
- 平均空腹血糖：{avg_fasting_glucose}mmol/L

我正在考虑吃{food_name}，这是一种{food_category}类食物。
其营养成分为：碳水{carbs}g，蛋白质{protein}g，脂肪{fat}g，GI值{gi}。

我的历史血糖反应记录：
{glucose_response_history}

请问这个食物对我血糖的影响如何？应该注意什么？
</USER>

<ASSISTANT>
{target_response}
</ASSISTANT>
```

### 8.5 模型集成与部署

#### 8.5.1 与现有记忆服务集成

在`MemoryProcessor`类中添加模型推理功能：

```python
# 扩展memory_processor.py
async def predict_glucose_response(self, user_id: int, food_id: int, quantity: float):
    """预测用户食用特定食物后的血糖反应"""
    # 1. 获取用户信息
    user = self.db.query(User).filter(User.id == user_id).first()
    
    # 2. 获取食物信息
    food = self.db.query(FoodNutrition).filter(FoodNutrition.id == food_id).first()
    
    # 3. 获取用户历史血糖响应
    history = self.db.query(FoodIntake)\
        .filter(FoodIntake.user_id == user_id)\
        .order_by(FoodIntake.intake_datetime.desc())\
        .limit(5)\
        .all()
    
    # 4. 构建推理提示词
    prompt = self._build_glucose_prediction_prompt(user, food, history, quantity)
    
    # 5. 调用微调后的模型
    response = await self.glucose_prediction_model.generate(prompt)
    
    return self._parse_glucose_prediction(response)
```

#### 8.5.2 模型量化部署

为支持边缘设备部署，采用4-bit量化技术：

```python
# 模型量化示例
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
from bitsandbytes.nn import Linear4bit

# 1. 加载微调后的模型
model_path = "./diabetes-assistant-model"
tokenizer = AutoTokenizer.from_pretrained(model_path)

# 2. 4-bit量化加载
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_quant_type="nf4",
    device_map="auto",
    trust_remote_code=True
)

# 3. 保存量化后的模型
model.save_pretrained("./diabetes-assistant-model-4bit")
tokenizer.save_pretrained("./diabetes-assistant-model-4bit")
```

### 8.6 评估与改进循环

采用以下指标评估模型性能：

1. **血糖预测准确度**：预测血糖变化与实际值的MAE（平均绝对误差）
2. **建议质量评估**：专业营养师对模型生成建议的评分
3. **用户满意度**：通过反馈按钮收集用户对建议的评价

建立持续改进循环：
- 每周汇总新收集的用户数据
- 每月进行一次模型再训练
- 季度进行一次完整的模型评估与优化

### 8.7 隐私与合规性

在模型训练过程中应特别注意：

1. **数据匿名化**：训练前移除所有可能的用户标识信息
2. **差分隐私**：应用差分隐私技术防止模型记忆敏感信息
3. **本地部署**：优先考虑边缘计算方案，避免敏感数据上传
